{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고려문과\n",
    "html = urlopen('http://people.aks.ac.kr/front/dirSer/exm/exmKingExmList.aks?classCode=KM&className=%EA%B3%A0%EB%A0%A4%EB%AC%B8%EA%B3%BC&isEQ=false&kristalSearchArea=P')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "king_href_list = []\n",
    "\n",
    "kings = soup.find_all('td', { 'headers': 'king_name' })\n",
    "for king in kings:\n",
    "    king_href = king.find('a', href=True)\n",
    "    king_href = king_href['href']\n",
    "    king_href = urllib.parse.quote_plus(king_href, safe='/?=&')\n",
    "    king_href = 'http://people.aks.ac.kr' + king_href\n",
    "    print(king_href)\n",
    "    king_href_list.append(king_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_href_list = []\n",
    "\n",
    "for king_href in king_href_list:\n",
    "    html = urlopen(king_href)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    exams = soup.find_all('td', { 'headers': 'king_name' })\n",
    "    for exam in exams:\n",
    "        exam_href = exam.find('a', href=True)\n",
    "        exam_href = exam_href['href']\n",
    "        exam_href = urllib.parse.quote_plus(exam_href, safe='/?=&')\n",
    "        exam_href = 'http://people.aks.ac.kr' + exam_href\n",
    "        print(exam_href)\n",
    "        exam_href_list.append(exam_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_href_list = []\n",
    "\n",
    "for exam_href in exam_href_list:\n",
    "    html = urlopen(exam_href)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    candidates = soup.find_all('td', { 'headers': 'fullname' })\n",
    "    for candidate in candidates:\n",
    "        cand_href = candidate.find('a', href=True)\n",
    "        cand_href = cand_href['href']\n",
    "        cand_href = urllib.parse.quote_plus(cand_href, safe='/?=&')\n",
    "        cand_href = 'http://people.aks.ac.kr' + cand_href\n",
    "        print(cand_href)\n",
    "        cand_href_list.append(cand_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_UCI = []\n",
    "\n",
    "for cand_href in cand_href_list:\n",
    "    html = urlopen(cand_href)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    name = soup.find('div', {'id': 'contentBody_title' })\n",
    "    uci = soup.find('a', {'id': 'uci'})\n",
    "    item = [cand_href, name.text.strip(), uci.text]\n",
    "    print(item)\n",
    "    name_UCI.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(name_UCI)\n",
    "df.to_csv('km_uci.csv', encoding='utf-8', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
